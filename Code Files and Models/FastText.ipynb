{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PranayNagrale/Multilingual_Cyberbullying_Detection/blob/main/Code%20Files%20and%20Models/FastText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkTOBTM3mjxx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ENV4Ic0l-hw"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/hatespeech/cyberbullying_training_dataset.csv')\n",
        "df.dropna(inplace = True)\n",
        "df.reset_index(drop = True, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eECEhzKrEDCa",
        "outputId": "f41c1a8e-4eaf-4c10-f563-14c59fe7c89b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115659"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh3pkcvfnbWE"
      },
      "outputs": [],
      "source": [
        "df.transformed_text = df.transformed_text.astype('str')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5tZgdQIOYiZ",
        "outputId": "d21709b5-fce1-4238-db98-f14446093acc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m61.4/68.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199772 sha256=0bd6e2611c920044cdd59fc5fd47dbad4c3e0670907bdbe808e53cf447d233e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmYuD39WT8Z7"
      },
      "outputs": [],
      "source": [
        "import fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K62UtWk4Odrd"
      },
      "outputs": [],
      "source": [
        "# Extract the text and label data\n",
        "text_data = df['transformed_text'].tolist()\n",
        "label_data = df['hate'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z8zM1ieOpvt"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/hatespeech/corpus.txt', 'w') as f:\n",
        "    for i in range(len(text_data)):\n",
        "        line = '__label__' + str(label_data[i]) + ' ' + text_data[i]\n",
        "        f.write(line + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iams4niDO9jr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(text_data, label_data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6R28KPFO3P7"
      },
      "outputs": [],
      "source": [
        "model_ft = fasttext.train_supervised('/content/drive/MyDrive/hatespeech/corpus.txt',dim=1500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1_jj4gGwT40"
      },
      "outputs": [],
      "source": [
        "# model_ft.save_model('/content/drive/MyDrive/cyberbulling/fasttext/fast_model.bin')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = fasttext.load_model('/content/drive/MyDrive/cyberbulling/fasttext/fast_model.bin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-31Jhd9LJQy",
        "outputId": "dd4dd653-53d7-49aa-e787-4d6da36ceaa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzdwAbLJLSGg",
        "outputId": "c4a46443-f843-4699-a0fe-4d7a0c6fc150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fasttext.FastText._FastText at 0x7aa0525ee6b0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = model.get_sentence_vector('hi')"
      ],
      "metadata": {
        "id": "FuNB5W2qLpCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape"
      ],
      "metadata": {
        "id": "wnihbm-gL9iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63b5f65-6627-4e45-8689-e5b83199750b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yr6OfsmzVmpy"
      },
      "outputs": [],
      "source": [
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_train_ft = []\n",
        "for sentence in X_train:\n",
        "    vector = model_ft.get_sentence_vector(sentence)\n",
        "    X_train_ft.append(vector)\n",
        "\n",
        "X_test_ft = []\n",
        "for sentence in X_test:\n",
        "    vector = model_ft.get_sentence_vector(sentence)\n",
        "    X_test_ft.append(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9Gr6--_WCgI"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z60xW9qAXMb8"
      },
      "outputs": [],
      "source": [
        "lrc = LogisticRegression(solver='liblinear', penalty='l1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLfuHgFUUbrs",
        "outputId": "7cd994e0-bcac-41bd-9aab-88cefa3e729e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9456596922012797\n",
            "0.9501242456514022\n",
            "0.9445498257532312\n",
            "0.939040435049557\n"
          ]
        }
      ],
      "source": [
        "# Train a logistic regression classifier on the FastText vectors\n",
        "lrc.fit(X_train_ft, y_train)\n",
        "\n",
        "# Test the classifier on the testing set\n",
        "y_pred_ft = lrc.predict(X_test_ft)\n",
        "\n",
        "\n",
        "print(accuracy_score(y_test, y_pred_ft))\n",
        "print(precision_score(y_test, y_pred_ft))\n",
        "print(f1_score(y_test, y_pred_ft))\n",
        "print(recall_score(y_test, y_pred_ft))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PIjDDCLf4qL"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB,BernoulliNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QErFxx2RFs6",
        "outputId": "ec2dff50-4b99-4d52-e94b-2038066a653c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9239581532076777\n",
            "0.9606344353143512\n",
            "0.9195591530616911\n",
            "0.8818524690816595\n"
          ]
        }
      ],
      "source": [
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_ft, y_train)\n",
        "\n",
        "# Test the classifier on the testing set\n",
        "y_pred_ft_gnb = gnb.predict(X_test_ft)\n",
        "\n",
        "\n",
        "print(accuracy_score(y_test, y_pred_ft_gnb))\n",
        "print(precision_score(y_test, y_pred_ft_gnb))\n",
        "print(f1_score(y_test, y_pred_ft_gnb))\n",
        "print(recall_score(y_test, y_pred_ft_gnb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlA3dzg_RFpi"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1fz33fYRFmX",
        "outputId": "f903adbd-a9bd-41de-ecb9-48f1488fb5bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9179059311775895\n",
            "0.9166082076464398\n",
            "0.9167287875465907\n",
            "0.9168493991755109\n"
          ]
        }
      ],
      "source": [
        "dtc = DecisionTreeClassifier()\n",
        "\n",
        "dtc.fit(X_train_ft, y_train)\n",
        "\n",
        "# Test the classifier on the testing set\n",
        "y_pred_ft_dtc = dtc.predict(X_test_ft)\n",
        "\n",
        "\n",
        "print(accuracy_score(y_test, y_pred_ft_dtc))\n",
        "print(precision_score(y_test, y_pred_ft_dtc))\n",
        "print(f1_score(y_test, y_pred_ft_dtc))\n",
        "print(recall_score(y_test, y_pred_ft_dtc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# pickle.dump(gnb,open('/content/drive/MyDrive/cyberbulling/fasttext/gnb_ft_model.pkl','wb'))\n",
        "# pickle.dump(lrc,open('/content/drive/MyDrive/cyberbulling/fasttext/lrc_ft_model.pkl','wb'))\n",
        "# pickle.dump(dtc,open('/content/drive/MyDrive/cyberbulling/fasttext/dtc_ft_model.pkl','wb'))"
      ],
      "metadata": {
        "id": "Izl2W1JIZaUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMU2rBzTRFcd",
        "outputId": "c9cd8cb5-c0fc-4cee-f1c8-23c04ccd667d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9430226526024554\n",
            "0.9442241607190061\n",
            "0.9420659340659341\n",
            "0.9399175510920095\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_ft, y_train)\n",
        "\n",
        "# Test the classifier on the testing set\n",
        "y_pred_ft_rf = rf.predict(X_test_ft)\n",
        "\n",
        "\n",
        "print(accuracy_score(y_test, y_pred_ft_rf))\n",
        "print(precision_score(y_test, y_pred_ft_rf))\n",
        "print(f1_score(y_test, y_pred_ft_rf))\n",
        "print(recall_score(y_test, y_pred_ft_rf))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle.dump(rf,open('/content/drive/MyDrive/cyberbulling/fasttext/rf_ft_model.pkl','wb'))"
      ],
      "metadata": {
        "id": "XlrCIlT6gC40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4EuBkv4ru7O"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySjfvw83CinI"
      },
      "outputs": [],
      "source": [
        "abc = AdaBoostClassifier(random_state=2)\n",
        "etc = ExtraTreesClassifier(n_estimators=100, random_state=2)\n",
        "gbdt = GradientBoostingClassifier(random_state=2)\n",
        "xgb = XGBClassifier(random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu8yTkH6Ciji",
        "outputId": "7e480212-633f-41e3-8e0d-a6c408a0a216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.9464378350337195\n",
            "precision score: 0.9467205908211711\n",
            "f1 score: 0.9455982436882546\n",
            "recall_score: 0.9444785545127621\n"
          ]
        }
      ],
      "source": [
        "abc.fit(X_train_ft,y_train)\n",
        "y_pred6 = abc.predict(X_test_ft)\n",
        "print(f'accuracy score: {accuracy_score(y_test,y_pred6)}')\n",
        "print(f'precision score: {precision_score(y_test,y_pred6)}')\n",
        "print(f'f1 score: {f1_score(y_test,y_pred6)}')\n",
        "print(f'recall_score: {recall_score(y_test,y_pred6)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle.dump(abc,open('/content/drive/MyDrive/cyberbulling/fasttext/abc_ft_model.pkl','wb'))"
      ],
      "metadata": {
        "id": "c1LyIfWAosaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph9FPMnWFCkY",
        "outputId": "0c71ebd0-4800-48dc-89ee-a22f6112b240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.9424174303994467\n",
            "precision score: 0.9414291977202981\n",
            "f1 score: 0.941594317284925\n",
            "recall_score: 0.9417594947811595\n"
          ]
        }
      ],
      "source": [
        "etc.fit(X_train_ft,y_train)\n",
        "y_pred7 = etc.predict(X_test_ft)\n",
        "print(f'accuracy score: {accuracy_score(y_test,y_pred7)}')\n",
        "print(f'precision score: {precision_score(y_test,y_pred7)}')\n",
        "print(f'f1 score: {f1_score(y_test,y_pred7)}')\n",
        "print(f'recall_score: {recall_score(y_test,y_pred7)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igSgDVIRCigo"
      },
      "outputs": [],
      "source": [
        "et = ExtraTreesClassifier(n_estimators=200, random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPiz5cRBCidw",
        "outputId": "2abbc1da-8f31-438c-90f4-97d303e96237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.9426768113435933\n",
            "precision score: 0.9415373827679901\n",
            "f1 score: 0.9418676019289786\n",
            "recall_score: 0.9421980528023858\n"
          ]
        }
      ],
      "source": [
        "et.fit(X_train_ft,y_train)\n",
        "y_pred7 = et.predict(X_test_ft)\n",
        "print(f'accuracy score: {accuracy_score(y_test,y_pred7)}')\n",
        "print(f'precision score: {precision_score(y_test,y_pred7)}')\n",
        "print(f'f1 score: {f1_score(y_test,y_pred7)}')\n",
        "print(f'recall_score: {recall_score(y_test,y_pred7)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle.dump(et,open('/content/drive/MyDrive/cyberbulling/fasttext/et_ft_model.pkl','wb'))"
      ],
      "metadata": {
        "id": "ajfKlbzur1m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ett = ExtraTreesClassifier(n_estimators=300, random_state=2)\n",
        "ett.fit(X_train_ft,y_train)\n",
        "y_pred7 = ett.predict(X_test_ft)\n",
        "print(f'accuracy score: {accuracy_score(y_test,y_pred7)}')\n",
        "print(f'precision score: {precision_score(y_test,y_pred7)}')\n",
        "print(f'f1 score: {f1_score(y_test,y_pred7)}')\n",
        "print(f'recall_score: {recall_score(y_test,y_pred7)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t671exisB7N",
        "outputId": "fe158053-35dc-4a61-c4ed-e4bc8ce609cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.943109112917171\n",
            "precision score: 0.9422081908269754\n",
            "f1 score: 0.9422908261708473\n",
            "recall_score: 0.9423734760108763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle.dump(ett,open('/content/drive/MyDrive/cyberbulling/fasttext/ett_ft_model.pkl','wb'))"
      ],
      "metadata": {
        "id": "t0evk9AbsHBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-Y7nhQSCiYl",
        "outputId": "06b6e969-03ae-4f1f-8737-d4ea3d418b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.9433252637039599\n",
            "precision score: 0.9424662339940362\n",
            "f1 score: 0.9425075647941061\n",
            "recall_score: 0.9425488992193667\n"
          ]
        }
      ],
      "source": [
        "xgb.fit(X_train_ft,y_train)\n",
        "y_pred9 = xgb.predict(X_test_ft)\n",
        "print(f'accuracy score: {accuracy_score(y_test,y_pred9)}')\n",
        "print(f'precision score: {precision_score(y_test,y_pred9)}')\n",
        "print(f'f1 score: {f1_score(y_test,y_pred9)}')\n",
        "print(f'recall_score: {recall_score(y_test,y_pred9)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYkpjUpXD0Xw",
        "outputId": "d23014db-0d1a-494f-ae35-f26795fa5710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.9501988587238458\n",
            "precision score: 0.9490842169836123\n",
            "f1 score: 0.9495002630194634\n",
            "recall_score: 0.949916673975967\n"
          ]
        }
      ],
      "source": [
        "xgb = XGBClassifier(n_estimators=20,random_state=2)\n",
        "xgb.fit(X_train_ft,y_train)\n",
        "y_pred9 = xgb.predict(X_test_ft)\n",
        "print(f'accuracy score: {accuracy_score(y_test,y_pred9)}')\n",
        "print(f'precision score: {precision_score(y_test,y_pred9)}')\n",
        "print(f'f1 score: {f1_score(y_test,y_pred9)}')\n",
        "print(f'recall_score: {recall_score(y_test,y_pred9)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle.dump(xgb,open('/content/drive/MyDrive/cyberbulling/fasttext/xgb_ft_model.pkl','wb'))\n"
      ],
      "metadata": {
        "id": "xek0knS52f2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "uRvlQQIeOo3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/cyberbulling/fasttext/xgb_ft_model.pkl', 'rb') as f:\n",
        "    xgb = pickle.load(f)\n",
        "\n",
        "bengali = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/bengali_test.csv')\n",
        "bengali.transformed_text = bengali.transformed_text.astype('str')\n",
        "X = bengali.transformed_text\n",
        "y = bengali.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = xgb.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCInhD6ROokk",
        "outputId": "54760ae9-38ac-4e88-ff23-71500df8aae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.8486666666666667\n",
            "precision score: 0.7573739295908658\n",
            "f1 score: 0.7781036168132943\n",
            "recall_score: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/english_test.csv')\n",
        "eng.transformed_text = eng.transformed_text.astype('str')\n",
        "X = eng.transformed_text\n",
        "y = eng.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = xgb.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOYcP42xPTqB",
        "outputId": "c7699252-2ec6-48f4-95cf-5c9c4fdc8969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.8587724063009234\n",
            "precision score: 0.904702455264253\n",
            "f1 score: 0.8931799506984388\n",
            "recall_score: 0.881947261663286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/hindi_test.csv')\n",
        "test.transformed_text = test.transformed_text.astype('str')\n",
        "X = test.transformed_text\n",
        "y = test.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = xgb.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GlPU-ajRves",
        "outputId": "5011bc18-aa47-4dcf-a829-98b2c64c2e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.86302780638517\n",
            "precision score: 0.8634886240520043\n",
            "f1 score: 0.8569892473118279\n",
            "recall_score: 0.8505869797225186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/hinglish_test.csv')\n",
        "test.transformed_text = test.transformed_text.astype('str')\n",
        "X = test.transformed_text\n",
        "y = test.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = xgb.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRB7A_8TRyC4",
        "outputId": "e75019bb-4716-4798-f4a4-fe1b3650963b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.8046585494970884\n",
            "precision score: 0.8378672470076169\n",
            "f1 score: 0.8067050811943425\n",
            "recall_score: 0.7777777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/marathi_test.csv')\n",
        "test.transformed_text = test.transformed_text.astype('str')\n",
        "X = test.transformed_text\n",
        "y = test.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = xgb.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZHzE3o5Rxus",
        "outputId": "46824ae1-f778-4be8-e707-71e45dc1b400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.9175764192139738\n",
            "precision score: 0.9121338912133892\n",
            "f1 score: 0.8965044551062372\n",
            "recall_score: 0.8814016172506739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/tamil_test.csv')\n",
        "test.transformed_text = test.transformed_text.astype('str')\n",
        "X = test.transformed_text\n",
        "y = test.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = xgb.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA8Aj5cmRvTu",
        "outputId": "ed7c2ddb-9121-42fe-cf61-bfbe820f7250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.7313974591651543\n",
            "precision score: 0.7319587628865979\n",
            "f1 score: 0.489655172413793\n",
            "recall_score: 0.36787564766839376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QX4GwPDYRLIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/cyberbulling/fasttext/abc_ft_model.pkl', 'rb') as f:\n",
        "    abc = pickle.load(f)\n",
        "\n",
        "bengali = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/bengali_test.csv')\n",
        "bengali.transformed_text = bengali.transformed_text.astype('str')\n",
        "X = bengali.transformed_text\n",
        "y = bengali.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = abc.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EphXy0QhUoqv",
        "outputId": "5a0753c0-71ce-4ec5-8585-aacd8308bb27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.8463333333333334\n",
            "precision score: 0.7422867513611615\n",
            "f1 score: 0.7801621363853123\n",
            "recall_score: 0.8221105527638191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/english_test.csv')\n",
        "eng.transformed_text = eng.transformed_text.astype('str')\n",
        "X = eng.transformed_text\n",
        "y = eng.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = abc.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXcQRNCaUoof",
        "outputId": "2a1a9e8f-3d14-4d77-a91f-7bf4f2a7e022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.8582292232482347\n",
            "precision score: 0.9036144578313253\n",
            "f1 score: 0.8928571428571428\n",
            "recall_score: 0.8823529411764706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/hindi_test.csv')\n",
        "test.transformed_text = test.transformed_text.astype('str')\n",
        "X = test.transformed_text\n",
        "y = test.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = abc.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl6DG4LKUolz",
        "outputId": "61867ef3-e42f-4339-b9ee-7fe4d32ee99f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.8578784757981462\n",
            "precision score: 0.8635863586358636\n",
            "f1 score: 0.8504875406283856\n",
            "recall_score: 0.8377801494130203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/hinglish_test.csv')\n",
        "test.transformed_text = test.transformed_text.astype('str')\n",
        "X = test.transformed_text\n",
        "y = test.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = abc.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlJNdt8jUohY",
        "outputId": "db7c2066-85fa-432e-d3a2-7fd6b8470248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.8051879301217575\n",
            "precision score: 0.8365800865800865\n",
            "f1 score: 0.8077324973876698\n",
            "recall_score: 0.7808080808080808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/marathi_test.csv')\n",
        "test.transformed_text = test.transformed_text.astype('str')\n",
        "X = test.transformed_text\n",
        "y = test.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = abc.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTaMr9IZUojv",
        "outputId": "04455a28-a114-4889-8b10-c32c6f8f011d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.9203056768558951\n",
            "precision score: 0.915041782729805\n",
            "f1 score: 0.9\n",
            "recall_score: 0.8854447439353099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/tamil_test.csv')\n",
        "test.transformed_text = test.transformed_text.astype('str')\n",
        "X = test.transformed_text\n",
        "y = test.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = abc.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGLSH8W3UobS",
        "outputId": "0b665262-44c1-4a4a-a85b-0c7ef666be00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.7168784029038112\n",
            "precision score: 0.6989247311827957\n",
            "f1 score: 0.4545454545454545\n",
            "recall_score: 0.33678756476683935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "cdGTCKAkJMX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/cyberbulling/fasttext/ett_ft_model.pkl', 'rb') as f:\n",
        "    ett = pickle.load(f)\n",
        "\n",
        "bengali = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/bengali_test.csv')\n",
        "bengali.transformed_text = bengali.transformed_text.astype('str')\n",
        "X = bengali.transformed_text\n",
        "y = bengali.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = ett.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFzQyFxUJMTf",
        "outputId": "9fed9b98-f4c0-4978-e9ca-007d5216957f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.8536666666666667\n",
            "precision score: 0.7622641509433963\n",
            "f1 score: 0.7863746958637471\n",
            "recall_score: 0.8120603015075377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/english_test.csv')\n",
        "test.transformed_text = test.transformed_text.astype('str')\n",
        "X = test.transformed_text\n",
        "y = test.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = ett.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "id": "tl0f5wRzUoX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04157fd0-69c8-4da8-bd1c-79c76c0165a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.8484519282998371\n",
            "precision score: 0.8938455183808344\n",
            "f1 score: 0.885796152271797\n",
            "recall_score: 0.8778904665314402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/hindi_test.csv')\n",
        "test.transformed_text = test.transformed_text.astype('str')\n",
        "X = test.transformed_text\n",
        "y = test.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = ett.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "id": "jglPYhZIUoU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85589ce1-47fb-44c3-81a8-dfa2fbeee5aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.8640576725025747\n",
            "precision score: 0.8677595628415301\n",
            "f1 score: 0.857451403887689\n",
            "recall_score: 0.847385272145144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/hinglish_test.csv')\n",
        "test.transformed_text = test.transformed_text.astype('str')\n",
        "X = test.transformed_text\n",
        "y = test.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = ett.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "id": "UqcS8juZUoR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffbccbda-887c-47cd-fee8-61a85e7896bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.8046585494970884\n",
            "precision score: 0.8430939226519337\n",
            "f1 score: 0.8052770448548814\n",
            "recall_score: 0.7707070707070707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/marathi_test.csv')\n",
        "test.transformed_text = test.transformed_text.astype('str')\n",
        "X = test.transformed_text\n",
        "y = test.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = ett.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "id": "abfMfBySUoPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504961e9-5906-4aff-c0a1-f94f512eab7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.9241266375545851\n",
            "precision score: 0.9216783216783216\n",
            "f1 score: 0.9045984900480439\n",
            "recall_score: 0.8881401617250674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/hate sppech dataset/test dataset/tamil_test.csv')\n",
        "test.transformed_text = test.transformed_text.astype('str')\n",
        "X = test.transformed_text\n",
        "y = test.hate\n",
        "# Get the vector representation of each sentence in the dataset using FastText\n",
        "X_test = []\n",
        "for sentence in X:\n",
        "    vector = model.get_sentence_vector(sentence)\n",
        "    X_test.append(vector)\n",
        "pred = ett.predict(X_test)\n",
        "print(f'accuracy score: {accuracy_score(y,pred)}')\n",
        "print(f'precision score: {precision_score(y,pred)}')\n",
        "print(f'f1 score: {f1_score(y,pred)}')\n",
        "print(f'recall_score: {recall_score(y,pred)}')"
      ],
      "metadata": {
        "id": "dXL12xuNUoLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73e601fb-16d7-4dc1-b905-664873e96682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score: 0.7277676950998185\n",
            "precision score: 0.7216494845360825\n",
            "f1 score: 0.48275862068965514\n",
            "recall_score: 0.3626943005181347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bhrf-cJjUoIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b1bGt1lvUoEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SZbn-efBSdcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HIUgsOmPSdY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XrtlUZxMSdQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JBZ4hsIoSc7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb"
      ],
      "metadata": {
        "id": "-mJ6l1xwRWs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AVzlOdU8RWpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2dAn2AaCRWlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PpGiBqxmRWhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SayEq-DzRWdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YzYrPiVCia-"
      },
      "outputs": [],
      "source": [
        "# more power is required to run this algorithm\n",
        "# gbdt.fit(X_train_ft,y_train)\n",
        "# y_pred8 = gbdt.predict(X_test_ft)\n",
        "# print(f'accuracy score: {accuracy_score(y_test,y_pred8)}')\n",
        "# print(f'precision score: {precision_score(y_test,y_pred8)}')\n",
        "# print(f'f1 score: {f1_score(y_test,y_pred8)}')\n",
        "# print(f'recall_score: {recall_score(y_test,y_pred8)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "more power is reqiured for voting and stacking classifier."
      ],
      "metadata": {
        "id": "MorfRsDSbuKt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6eyOoHwD0Nl"
      },
      "outputs": [],
      "source": [
        "# Voting Classifier\n",
        "# from sklearn.ensemble import VotingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbTmK3IMD0Kk"
      },
      "outputs": [],
      "source": [
        "# voting = VotingClassifier(estimators=[('lrc', lrc), ('xgb', xgb),('etc', etc),('rfc', rfc),],voting='soft')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqALKCCwBzdl"
      },
      "outputs": [],
      "source": [
        "# voting.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bwOrpwoBzZv"
      },
      "outputs": [],
      "source": [
        "# y_pred = voting.predict(X_test)\n",
        "# print(\"Accuracy\",accuracy_score(y_test,y_pred))\n",
        "# print(\"Precision\",precision_score(y_test,y_pred))\n",
        "# print(f'f1 score: {f1_score(y_test,y_pred)}')\n",
        "# print(f'recall_score: {recall_score(y_test,y_pred)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bEwt_8uo3Xor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R3w7e7bq3Z2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hFkWZZ-w3eEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "06Rsj11s3jZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Import the libraries\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # Define the data and the target\n",
        "# X = X_train_ft # The features\n",
        "# y = t # The labels\n",
        "\n",
        "# # Define the base model\n",
        "# rf = RandomForestClassifier()\n",
        "\n",
        "# # Define the parameter grid or distribution\n",
        "# param_grid = {\n",
        "#     'n_estimators': [100, 200, 300, 400, 500],\n",
        "#     'criterion': ['gini', 'entropy'],\n",
        "#     'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "#     'min_samples_split': [2, 4, 6, 8, 10],\n",
        "#     'min_samples_leaf': [1, 2, 3, 4, 5],\n",
        "#     'max_features': ['auto', 'sqrt', 'log2', 0.2, 0.4, 0.6, 0.8],\n",
        "#     'bootstrap': [True, False]\n",
        "# }\n",
        "\n",
        "# # Define the scoring function\n",
        "# scoring = 'accuracy'\n",
        "\n",
        "# # Define the cross-validation strategy\n",
        "# cv = 5\n",
        "\n",
        "# # Perform grid search or random search\n",
        "# grid_search = GridSearchCV(rf, param_grid, scoring, cv)\n",
        "# random_search = RandomizedSearchCV(rf, param_grid, scoring, cv)\n",
        "\n",
        "# # Fit the data to the search object\n",
        "# grid_search.fit(X, y)\n",
        "# random_search.fit(X, y)\n",
        "\n",
        "# # Get the best model and the best parameters\n",
        "# best_model_grid = grid_search.best_estimator_\n",
        "# best_params_grid = grid_search.best_params_\n",
        "# best_model_random = random_search.best_estimator_\n",
        "# best_params_random = random_search.best_params_\n",
        "\n",
        "# # Print the results\n",
        "# print(\"Best model from grid search:\")\n",
        "# print(best_model_grid)\n",
        "# print(\"Best parameters from grid search:\")\n",
        "# print(best_params_grid)\n",
        "# print(\"Best model from random search:\")\n",
        "# print(best_model_random)\n",
        "# print(\"Best parameters from random search:\")\n",
        "# print(best_params_random)\n"
      ],
      "metadata": {
        "id": "eLkJLqfJqypd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "87bjWtxv3HpF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1h_WILlsqx3Q-f4ChHiY2J4x58YmxNw7G",
      "authorship_tag": "ABX9TyOj7PHOJQqcce/eLHJKkwdF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}